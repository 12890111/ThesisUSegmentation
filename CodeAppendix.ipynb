{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54f850e-541f-4d8d-9912-98f482bd1d5f",
   "metadata": {},
   "source": [
    "## Old resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1371475e-19d7-40d2-9b94-d69b923866c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_images(images, desired_size=(192, 384)):\n",
    "#     resized_images = []\n",
    "    \n",
    "#     # loop and resize for all images\n",
    "#     for img in images:\n",
    "#         old_size = img.shape[:2]\n",
    "\n",
    "#         # measure difference between the current and desired size\n",
    "#         delta_w = desired_size[1] - old_size[1]\n",
    "#         delta_h = desired_size[0] - old_size[0]\n",
    "\n",
    "#         # determine padding or cropping for width and height\n",
    "#         if delta_w >= 0:\n",
    "#             left, right = delta_w // 2, delta_w - (delta_w // 2)\n",
    "#         else:\n",
    "#             left, right = 0, 0\n",
    "#             img = img[:, -delta_w // 2:old_size[1] + delta_w // 2]\n",
    "\n",
    "#         if delta_h >= 0:\n",
    "#             top, bottom = delta_h // 2, delta_h - (delta_h // 2)\n",
    "#         else:\n",
    "#             top, bottom = 0, 0\n",
    "#             img = img[-delta_h // 2:old_size[0] + delta_h // 2, :]\n",
    "\n",
    "#         # set the color to greyscale for the images\n",
    "#         color = [0, 0, 0] if len(img.shape) == 3 else 0\n",
    "\n",
    "#         # apply padding\n",
    "#         new_img = np.pad(img, ((top, bottom), (left, right), (0, 0)) if len(img.shape) == 3 else ((top, bottom), (left, right)), 'constant', constant_values=color)\n",
    "        \n",
    "#         resized_images.append(new_img)\n",
    "    \n",
    "#     return np.array(resized_images)\n",
    "\n",
    "# input_size = (192,384)\n",
    "\n",
    "# # Apply resizing to X and Y data\n",
    "# X_train_resized = resize_images(X_train, desired_size=input_size)\n",
    "# X_test_resized = resize_images(X_test, desired_size=input_size)\n",
    "# X_val_resized = resize_images(X_val, desired_size=input_size)\n",
    "\n",
    "# Y_train_resized = resize_images(Y_train, desired_size=input_size)\n",
    "# Y_test_resized = resize_images(Y_test, desired_size=input_size)\n",
    "# Y_val_resized = resize_images(Y_val, desired_size=input_size)\n",
    "\n",
    "\n",
    "# # retype data to uint8 to reduce computational load\n",
    "# Y_train_resized = Y_train_resized.astype(np.uint8)\n",
    "# Y_test_resized = Y_test_resized.astype(np.uint8)\n",
    "# Y_val_resized = Y_val_resized.astype(np.uint8)\n",
    "\n",
    "# X_train_resized = X_train_resized.astype(np.uint8)\n",
    "# X_test_resized = X_test_resized.astype(np.uint8)\n",
    "# X_val_resized = X_val_resized.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbf416-34ae-43bc-94bd-fc05889e0d1c",
   "metadata": {},
   "source": [
    "## Val and test set swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a4bfd-d5fe-471f-bfa5-0092567f552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = X_test_resized\n",
    "# X_test_resized = X_val_resized\n",
    "# X_val_resized = A\n",
    "\n",
    "# B = Y_test_resized\n",
    "# Y_test_resized = Y_val_resized\n",
    "# Y_val_resized = B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0deaca-4cb5-4908-a3fe-dd1c2cbf4d33",
   "metadata": {},
   "source": [
    "## Converting to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6875e9c8-dcce-4df4-b4c7-23c0a13d2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Assuming X_train_resized is your input array with shape (1307, 192, 384)\n",
    "# # Create an output array with shape (1307, 192, 384, 3) for RGB images\n",
    "# X_train_rgb = np.zeros((X_train_resized.shape[0], X_train_resized.shape[1], X_train_resized.shape[2], 3), dtype=np.uint8)\n",
    "# X_val_rgb = np.zeros((X_val_resized.shape[0], X_val_resized.shape[1], X_val_resized.shape[2], 3), dtype=np.uint8)\n",
    "# X_test_rgb = np.zeros((X_test_resized.shape[0], X_test_resized.shape[1], X_test_resized.shape[2], 3), dtype=np.uint8)\n",
    "\n",
    "# # Iterate over the images and convert them to RGB\n",
    "# for i in range(X_train_resized.shape[0]):\n",
    "#     # Each image is taken from the grayscale array and stacked to create an RGB image\n",
    "#     X_train_rgb[i] = np.stack((X_train_resized[i],) * 3, axis=-1)\n",
    "# for i in range(X_val_resized.shape[0]):\n",
    "#     # Each image is taken from the grayscale array and stacked to create an RGB image\n",
    "#     X_val_rgb[i] = np.stack((X_val_resized[i],) * 3, axis=-1)\n",
    "# for i in range(X_test_resized.shape[0]):\n",
    "# # Each image is taken from the grayscale array and stacked to create an RGB image\n",
    "#     X_test_rgb[i] = np.stack((X_test_resized[i],) * 3, axis=-1)\n",
    "\n",
    "# X_train_resized = X_train_rgb\n",
    "# X_val_resized = X_val_rgb\n",
    "# X_test_resized = X_test_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e8128-01b9-430c-a1f8-4146dfd399a6",
   "metadata": {},
   "source": [
    "## resizing images to different pixel amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c29102-11bf-4ae8-ae2a-d5192f79b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import os\n",
    "\n",
    "# def resize_image(image, size):\n",
    "#     return cv2.resize(image,size)\n",
    "# size = (256,256)\n",
    "\n",
    "# X_train_resized = [resize_image(img,size) for img in X_train_resized]\n",
    "# X_test_resized = [resize_image(img,size) for img in X_test_resized]\n",
    "# X_val_resized = [resize_image(img,size) for img in X_val_resized]\n",
    "\n",
    "# Y_train_resized = [resize_image(img,size) for img in Y_train_resized]\n",
    "# Y_test_resized = [resize_image(img,size) for img in Y_test_resized]\n",
    "# Y_val_resized = [resize_image(img,size) for img in Y_val_resized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e491d-385a-4ba7-ba65-ec04cf403a49",
   "metadata": {},
   "source": [
    "## Square images for trans/swin_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02133327-e9b4-409d-a18a-5f0cc24c9a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageOps\n",
    "# import numpy as np\n",
    "\n",
    "# def make_square(img_array):\n",
    "#     \"\"\"\n",
    "#     Adds padding to the image to make it square with a size of 384x384.\n",
    "\n",
    "#     Parameters:\n",
    "#     img_array (np.array): The input image as a numpy array.\n",
    "\n",
    "#     Returns:\n",
    "#     Image: The squared image with padding.\n",
    "#     \"\"\"\n",
    "#     # Convert numpy array to PIL Image\n",
    "#     img = Image.fromarray(img_array)\n",
    "\n",
    "#     # Desired dimensions\n",
    "#     desired_size = 384\n",
    "#     width, height = img.size\n",
    "\n",
    "#     # Calculate padding sizes\n",
    "#     delta_w = desired_size - width\n",
    "#     delta_h = desired_size - height\n",
    "#     padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
    "\n",
    "#     # Add padding to the image\n",
    "#     new_image = ImageOps.expand(img, padding, fill=0)  \n",
    "\n",
    "#     return new_image\n",
    "\n",
    "# # Example usage with a list of grayscale numpy arrays\n",
    "# X_train_squared = [make_square(img) for img in X_train_resized]\n",
    "\n",
    "# # Optionally convert the squared images back to numpy arrays if needed\n",
    "# X_train_resized = [np.array(make_square(img)) for img in X_train_resized]\n",
    "# X_test_resized = [np.array(make_square(img)) for img in X_test_resized]\n",
    "# X_val_resized = [np.array(make_square(img)) for img in X_val_resized]\n",
    "\n",
    "# Y_train_resized = [np.array(make_square(img)) for img in Y_train_resized]\n",
    "# Y_test_resized = [np.array(make_square(img)) for img in Y_test_resized]\n",
    "# Y_val_resized = [np.array(make_square(img)) for img in Y_val_resized]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586f6a4c-e4df-4e73-afb4-ca0f4db59c4e",
   "metadata": {},
   "source": [
    "## Randomizing data allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bae6cb-00c1-4b57-ba33-37e65894f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_train)\n",
    "Y = np.array(Y_train)\n",
    "# set random new indices for each image and apply them\n",
    "indices = np.random.permutation(len(X_train))\n",
    "X_shuffled = X[indices]\n",
    "Y_shuffled = Y[indices]\n",
    "\n",
    "Y_train = Y_shuffled\n",
    "X_train = X_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343620e2-d238-472e-bb17-c1777a454544",
   "metadata": {},
   "source": [
    "## Visualise Sobel filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bd33d9-36b6-46aa-a050-709195fe5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming your image is stored in a NumPy array called `image`\n",
    "# # Let's create a sample image for demonstration purposes\n",
    "# # Replace this with your actual image loading code\n",
    "# image = X_train_resized[0]\n",
    "\n",
    "# # Apply the Sobel filter\n",
    "# sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=21)  # Gradient in x direction\n",
    "# sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=21)  # Gradient in y direction\n",
    "\n",
    "# # Compute the magnitude of the gradient\n",
    "# sobel_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "# # Normalize the magnitude to the range [0, 255]\n",
    "# sobel_magnitude = cv2.normalize(sobel_magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# # Convert back to uint8\n",
    "# sobel_magnitude = sobel_magnitude.astype(np.uint8)\n",
    "\n",
    "# # Display the original and Sobel filtered images\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.title('Original Image')\n",
    "# plt.imshow(image, cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.title('Sobel X')\n",
    "# plt.imshow(sobel_x, cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.title('Sobel Y')\n",
    "# plt.imshow(sobel_y, cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.title('Sobel Magnitude')\n",
    "# plt.imshow(sobel_magnitude, cmap='gray')\n",
    "# plt.axis('off')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29fe32d-8386-4268-a06e-faf8e47bb81e",
   "metadata": {},
   "source": [
    "## Regular data augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac93a03-25ce-4576-a41a-9ec1b3568cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gen_args = dict(\n",
    "#     zoom_range=0.3,\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=False,\n",
    "#     fill_mode='nearest',\n",
    "# )\n",
    "\n",
    "# # Create an instance of ImageDataGenerator\n",
    "# image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# # Reshape the input data to match the expected shape\n",
    "# # Assuming X_train_normalized and Y_train_categorical are numpy arrays\n",
    "# X_train_normalized_reshaped = X_train_normalized.reshape(-1, 192, 384, 1)  # Assuming grayscale images\n",
    "# Y_train_categorical_reshaped = Y_train_categorical.reshape(-1, 192, 384, 4)  # Adjust num_classes accordingly\n",
    "\n",
    "# # Create the generator\n",
    "# train_generator = image_datagen.flow(X_train_normalized_reshaped, Y_train_categorical_reshaped, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab1728-f9bf-402c-a968-40272a73f63e",
   "metadata": {},
   "source": [
    "## Visualise the segmentation labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27239ad2-08d0-4319-95db-09310b90d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming seg_mask is your segmentation mask with values representing different classes\n",
    "# # And class_num is the class number you want to visualize (e.g., class number 1)\n",
    "# class_num = 1\n",
    "\n",
    "# # Extract pixels corresponding to the specified class\n",
    "# class_pixels = (true_mask == class_num).astype(int)\n",
    "\n",
    "# # Plot the extracted class pixels\n",
    "# plt.imshow(class_pixels, cmap='gray')\n",
    "# plt.title('Class {} Pixels'.format(class_num))\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c724a6b-87b0-4e0e-9330-11055a62f8f0",
   "metadata": {},
   "source": [
    "## Gif Image of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83abc76-5d4b-487a-9673-d6314f4db2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# output_path = 'combined_animation.gif'\n",
    "\n",
    "# # Initialize the counter\n",
    "# counter = 1\n",
    "\n",
    "# # Define a common size for all images\n",
    "# common_height = 384  # You can choose an appropriate height\n",
    "# common_width = 256   # You can choose an appropriate width for each image\n",
    "\n",
    "# # loop through each image\n",
    "# with imageio.get_writer(output_path, mode='I') as writer:\n",
    "#     for y_test, pred in zip(Y_test_categorical, predictions):\n",
    "        \n",
    "#         # Load and convert each image\n",
    "#         true_mask = np.uint8(y_test / np.max(y_test) * 255)\n",
    "#         predicted_mask = np.uint8(pred / np.max(pred) * 255)\n",
    "        \n",
    "#         # Resize images to have the same dimensions\n",
    "#         ultrasound_image = cv2.resize(ultrasound_image, (common_width, common_height), interpolation=cv2.INTER_AREA)\n",
    "#         true_mask = cv2.resize(true_mask, (common_width, common_height), interpolation=cv2.INTER_AREA)\n",
    "#         predicted_mask = cv2.resize(predicted_mask, (common_width, common_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#         # Concatenate images side to side\n",
    "#         combined_image = np.concatenate((ultrasound_image, true_mask, predicted_mask), axis=1)\n",
    "        \n",
    "#         # Convert to a color image if it's not already\n",
    "#         if combined_image.ndim == 2 or (combined_image.ndim == 3 and combined_image.shape[2] == 1):\n",
    "#             combined_image = cv2.cvtColor(combined_image, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "#         # Define the font, scale, color, and thickness of the counter text\n",
    "#         font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#         scale = 1\n",
    "#         color = (255, 0, 0)  # Blue color in BGR\n",
    "#         thickness = 2\n",
    "        \n",
    "#         # Position of the counter text\n",
    "#         position = (10, 30) \n",
    "        \n",
    "#         # Put the counter text on the combined image\n",
    "#         cv2.putText(combined_image, f'Image: {counter}', position, font, scale, color, thickness)\n",
    "        \n",
    "#         # Save the slice with the counter\n",
    "#         writer.append_data(combined_image)\n",
    "        \n",
    "#         # Increment the counter\n",
    "#         counter += 1 \n",
    "        \n",
    "# # # Display the final animation\n",
    "# from IPython.display import Image\n",
    "# Image(filename=output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d1487-19e4-4043-8068-4b28fd770615",
   "metadata": {},
   "source": [
    "## Medsam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c517e1-840e-45bd-918a-d1cc78f96e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# from transformers import SamModel, SamProcessor\n",
    "# import torch\n",
    "# %matplotlib inline\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = SamModel.from_pretrained(\"flaviagiammarino/medsam-vit-base\").to(device)\n",
    "# processor = SamProcessor.from_pretrained(\"flaviagiammarino/medsam-vit-base\")\n",
    "\n",
    "# img_url = \"https://huggingface.co/flaviagiammarino/medsam-vit-base/resolve/main/scripts/input.png\"\n",
    "# raw_image = np.stack((X_test_normalized[0],)*3, axis=-1)\n",
    "\n",
    "# input_boxes = [95., 255., 190., 350.]\n",
    "\n",
    "# inputs = processor(raw_image, input_boxes=[[input_boxes]], return_tensors=\"pt\").to(device)\n",
    "# outputs = model(**inputs, multimask_output=False,do_rescale=False)\n",
    "# probs = processor.image_processor.post_process_masks(outputs.pred_masks.sigmoid().cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu(), binarize=False)\n",
    "\n",
    "# def show_mask(mask, ax, random_color):\n",
    "#     if random_color:\n",
    "#         color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "#     else:\n",
    "#         color = np.array([251/255, 252/255, 30/255, 0.6])\n",
    "#     h, w = mask.shape[-2:]\n",
    "#     mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "#     ax.imshow(mask_image)\n",
    "\n",
    "# def show_box(box, ax):\n",
    "#     x0, y0 = box[0], box[1]\n",
    "#     w, h = box[2] - box[0], box[3] - box[1]\n",
    "#     ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=\"blue\", facecolor=(0, 0, 0, 0), lw=2))\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "# ax[0].imshow(np.array(raw_image))\n",
    "# show_box(input_boxes, ax[0])\n",
    "# ax[0].set_title(\"Input Image and Bounsding Box\")\n",
    "# ax[0].axis(\"off\")\n",
    "# ax[1].imshow(np.array(raw_image))\n",
    "# show_mask(mask=probs[0] > 0.5, ax=ax[1], random_color=False)\n",
    "# show_box(input_boxes, ax[1])\n",
    "# ax[1].set_title(\"MedSAM Segmentation\")\n",
    "# ax[1].axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942378ee-4155-4077-8035-e974e5ff9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.memory_allocated())\n",
    "# print(torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae229ce5-bbd1-4c35-b1df-074ffc723f64",
   "metadata": {},
   "source": [
    "## Generating the dataset for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a67c1d-f317-4977-86fd-4c29ff2f99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dir = 'Segmentations'\n",
    "\n",
    "# for run in range(50,93):\n",
    "#     model_path = f'Model_run/Model_{run}'\n",
    "#     if not os.path.exists(model_path):\n",
    "#         print(f'Model not found at {model_path}, skipping this iteration.')\n",
    "#         continue\n",
    "#     try:\n",
    "#         # Load the model\n",
    "#         model = tf.keras.models.load_model(model_path, custom_objects={'custom_dice_loss': custom_dice_loss})\n",
    "#     except Exception as e:\n",
    "#         print(f'Error loading model from {model_path}: {e}')\n",
    "#         continue\n",
    "\n",
    "#     # Evaluate the model\n",
    "#     try:\n",
    "#         eval_result = model.evaluate(X_test_normalized, Y_test_categorical)\n",
    "#         print(f'Evaluation result for Model_{run}: {eval_result}')\n",
    "#     except Exception as e:\n",
    "#         print(f'Error evaluating model from {model_path}: {e}')\n",
    "#         continue\n",
    "\n",
    "#     # Make predictions\n",
    "#     try:\n",
    "#         predictions = model.predict(X_test_normalized)\n",
    "#     except Exception as e:\n",
    "#         print(f'Error making predictions with model from {model_path}: {e}')\n",
    "#         continue\n",
    "#     save_dir = f'Segmentations/Model_{run}'\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     for i, prediction in enumerate(predictions):\n",
    "#         file_path = os.path.join(save_dir, f'segmentation_{i}.npy')\n",
    "#         np.save(file_path, prediction)\n",
    "#     print(f'Saved predictions for model {run} to {save_dir}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12d913-6c94-4b91-886b-2de7eb22e723",
   "metadata": {},
   "source": [
    "## Load in a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29c3f86-22a0-4125-87fd-ff91fdc04ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = f'Model_run/Model_104'\n",
    "# model = tf.keras.models.load_model(model_path, custom_objects={'custom_dice_loss': custom_dice_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb32782-76ea-449c-9c64-1265bb8a2722",
   "metadata": {},
   "source": [
    "## Calculate median deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75517064-3832-4834-a662-f17e4038393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Example data: accuracy scores (for demonstration, replace these with your actual data)\n",
    "\n",
    "# accuracy_scores = iou_scores\n",
    "\n",
    "# # Calculate mean and standard deviation\n",
    "# mean_accuracy = np.mean(accuracy_scores)\n",
    "# std_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "# # Calculate mean ± standard deviation\n",
    "# accuracy_plus_std = mean_accuracy + std_accuracy\n",
    "# accuracy_minus_std = mean_accuracy - std_accuracy\n",
    "\n",
    "# print(f\"Mean Accuracy: {mean_accuracy:.2f}\")\n",
    "# print(f\"Standard Deviation: {std_accuracy:.2f}\")\n",
    "# print(f\"Accuracy + Std Dev: {accuracy_plus_std:.2f}\")\n",
    "# print(f\"Accuracy - Std Dev: {accuracy_minus_std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f29dcc-6202-426d-b686-8dcd93ef7cd4",
   "metadata": {},
   "source": [
    "## Visualize the dispersion of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2b450-107d-44e1-9e43-ecdcf0a7df9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dice_scores_patient1 = muscle_dice_scores[:195]\n",
    "# dice_scores_patient2 = muscle_dice_scores[195:]\n",
    "\n",
    "# # Create indices for each group\n",
    "# indices_patient1 = list(range(195))\n",
    "# indices_patient2 = list(range(195, 417))\n",
    "\n",
    "# # Plot the dice scores for both patients\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(indices_patient1, dice_scores_patient1, label='Patient 1')\n",
    "# plt.plot(indices_patient2, dice_scores_patient2, label='Patient 2', color='orange')\n",
    "# plt.xlabel('Image Index')\n",
    "# plt.ylabel('Dice Score')\n",
    "# plt.title('Dice Score Over Time for Two Patients')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8c61e-3080-455e-a50b-e18193eb6438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Define the dice scores for each class\n",
    "# dice_scores_patient1_muscle = muscle_dice_scores[:195]\n",
    "# dice_scores_patient2_muscle = muscle_dice_scores[195:]\n",
    "\n",
    "# dice_scores_patient1_tissue = tissue_dice_scores[:195]\n",
    "# dice_scores_patient2_tissue = tissue_dice_scores[195:]\n",
    "\n",
    "# dice_scores_patient1_fat = fat_dice_scores[:195]\n",
    "# dice_scores_patient2_fat = fat_dice_scores[195:]\n",
    "\n",
    "# dice_scores_patient1_outside = outside_dice_scores[:195]\n",
    "# dice_scores_patient2_outside = outside_dice_scores[195:]\n",
    "\n",
    "# # Create indices for each group\n",
    "# indices_patient1 = list(range(195))\n",
    "# indices_patient2 = list(range(195, 417))\n",
    "\n",
    "# # Determine the common y-axis range based on the overall min and max values\n",
    "# all_scores = (\n",
    "#     dice_scores_patient1_muscle + dice_scores_patient2_muscle +\n",
    "#     dice_scores_patient1_tissue + dice_scores_patient2_tissue +\n",
    "#     dice_scores_patient1_fat + dice_scores_patient2_fat +\n",
    "#     dice_scores_patient1_outside + dice_scores_patient2_outside\n",
    "# )\n",
    "# y_min = min(all_scores)\n",
    "# y_max = max(all_scores)\n",
    "\n",
    "# # Create the figure and subplots\n",
    "# fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# # Plot for Muscle\n",
    "# axs[0, 0].plot(indices_patient1, dice_scores_patient1_muscle, label='Patient 1')\n",
    "# axs[0, 0].plot(indices_patient2, dice_scores_patient2_muscle, label='Patient 2', color='orange')\n",
    "# axs[0, 0].set_title('Muscle Dice Score Over Time')\n",
    "# axs[0, 0].set_xlabel('Image Index')\n",
    "# axs[0, 0].set_ylabel('Dice Score')\n",
    "# axs[0, 0].legend()\n",
    "# axs[0, 0].grid(True)\n",
    "# axs[0, 0].set_ylim(y_min, y_max)\n",
    "\n",
    "# # Plot for Other Tissues\n",
    "# axs[0, 1].plot(indices_patient1, dice_scores_patient1_tissue, label='Patient 1')\n",
    "# axs[0, 1].plot(indices_patient2, dice_scores_patient2_tissue, label='Patient 2', color='orange')\n",
    "# axs[0, 1].set_title('Other Tissues Dice Score Over Time')\n",
    "# axs[0, 1].set_xlabel('Image Index')\n",
    "# axs[0, 1].set_ylabel('Dice Score')\n",
    "# axs[0, 1].legend()\n",
    "# axs[0, 1].grid(True)\n",
    "# axs[0, 1].set_ylim(y_min, y_max)\n",
    "\n",
    "# # Plot for Fat\n",
    "# axs[1, 0].plot(indices_patient1, dice_scores_patient1_fat, label='Patient 1')\n",
    "# axs[1, 0].plot(indices_patient2, dice_scores_patient2_fat, label='Patient 2', color='orange')\n",
    "# axs[1, 0].set_title('Fat Dice Score Over Time')\n",
    "# axs[1, 0].set_xlabel('Image Index')\n",
    "# axs[1, 0].set_ylabel('Dice Score')\n",
    "# axs[1, 0].legend()\n",
    "# axs[1, 0].grid(True)\n",
    "# axs[1, 0].set_ylim(y_min, y_max)\n",
    "\n",
    "# # Plot for Outside POV\n",
    "# axs[1, 1].plot(indices_patient1, dice_scores_patient1_outside, label='Patient 1')\n",
    "# axs[1, 1].plot(indices_patient2, dice_scores_patient2_outside, label='Patient 2', color='orange')\n",
    "# axs[1, 1].set_title('Outside POV Dice Score Over Time')\n",
    "# axs[1, 1].set_xlabel('Image Index')\n",
    "# axs[1, 1].set_ylabel('Dice Score')\n",
    "# axs[1, 1].legend()\n",
    "# axs[1, 1].grid(True)\n",
    "# axs[1, 1].set_ylim(y_min, y_max)\n",
    "\n",
    "# # Adjust layout and show the plot\n",
    "# plt.tight_layout()\n",
    "# filename = '67classWavelet denoising.png'\n",
    "# plt.savefig(filename)\n",
    "# plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
